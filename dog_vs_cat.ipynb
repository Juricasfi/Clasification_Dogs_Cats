{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"train\")\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una funciónpara crear un subset\n",
    "\n",
    "se crea un subset de entrenamiento con las primeras 1000 imagenes de cada categoría\n",
    "se crea un subset validation de 500 y uno de test de 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] No se puede crear un archivo que ya existe: 'cats_vs_dogs_small\\\\train\\\\cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Julian Castellanos\\Documents\\Inteligencia Artificial\\VisionArtificial\\dog-vs-cat\\dog_vs_cat.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m fnames:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             shutil\u001b[39m.\u001b[39mcopyfile(src \u001b[39m=\u001b[39m original_dir \u001b[39m/\u001b[39m fname, dst \u001b[39m=\u001b[39m \u001b[39mdir\u001b[39m \u001b[39m/\u001b[39m fname)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m make_subset(\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, start_index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, end_index\u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m make_subset(\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m, start_index\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, end_index\u001b[39m=\u001b[39m \u001b[39m1500\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m make_subset(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, start_index\u001b[39m=\u001b[39m\u001b[39m1500\u001b[39m, end_index\u001b[39m=\u001b[39m \u001b[39m2500\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Julian Castellanos\\Documents\\Inteligencia Artificial\\VisionArtificial\\dog-vs-cat\\dog_vs_cat.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m category \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mcat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdog\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mdir\u001b[39m \u001b[39m=\u001b[39m new_base_dir\u001b[39m/\u001b[39msubset_name\u001b[39m/\u001b[39mcategory\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(\u001b[39mdir\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     fnames \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcategory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m               \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_index,end_index)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Castellanos/Documents/Inteligencia%20Artificial/VisionArtificial/dog-vs-cat/dog_vs_cat.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m fnames:\n",
      "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] No se puede crear un archivo que ya existe: 'cats_vs_dogs_small\\\\train\\\\cat'"
     ]
    }
   ],
   "source": [
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir/subset_name/category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\"\n",
    "                  for i in range(start_index,end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src = original_dir / fname, dst = dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index= 1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index= 1500)\n",
    "make_subset(\"test\", start_index=1500, end_index= 2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape = (180,180,3)) ## Las imagenes son RGB de 180x180 pixeles\n",
    "x = layers.Rescaling(1./255)(inputs)  ## reescalar la entrada entre 0-1\n",
    "x = layers.Conv2D(filters = 32, kernel_size = 3, activation = \"relu\") (x)\n",
    "x = layers.MaxPooling2D(pool_size = 2) (x)\n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, activation = \"relu\") (x)\n",
    "x = layers.MaxPooling2D(pool_size = 2) (x)\n",
    "x = layers.Conv2D(filters = 128, kernel_size = 3, activation = \"relu\") (x)\n",
    "x = layers.MaxPooling2D(pool_size = 2) (x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size = 3, activation = \"relu\") (x)\n",
    "x = layers.MaxPooling2D(pool_size = 2) (x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size = 3, activation = \"relu\") (x)\n",
    "x = layers.Flatten() (x)\n",
    "\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\") (x)\n",
    "model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 178, 178, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 89, 89, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 87, 87, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 43, 43, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 41, 41, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 20, 20, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 9, 9, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 12545     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 991041 (3.78 MB)\n",
      "Trainable params: 991041 (3.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_Crossentropy\", optimizer = \"rmsprop\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesamiento de datos\n",
    "\n",
    "1. leer la imagenes\n",
    "2. Decodificar de jpg a RGB\n",
    "3. Convertir la informacion a Tensores de punto flotante\n",
    "4. Modificar el tamaño de la imagen a 180x180\n",
    "5. empaquetar en lotes de 32 imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(new_base_dir / \"train\",\n",
    "                                              image_size = (180, 180),\n",
    "                                              batch_size = 32)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(new_base_dir / \"validation\",\n",
    "                                              image_size = (180, 180),\n",
    "                                              batch_size = 32)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(new_base_dir / \"test\",\n",
    "                                              image_size = (180, 180),\n",
    "                                              batch_size = 32)\n",
    "\n",
    "## los datasets son del tamaño (32, 180, 180, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto datasets es un  iterador, está creado para realizar una eficiente entrada  para los modelos de ML\n",
    "\n",
    "Normalmente retorna lotes con datos y etiquetas\n",
    "Se pueden pasar los datasets directamente al metodo fit\n",
    "\n",
    "funciona asincronamente, mientras procesa nuevos datos los otros están siendo manejados por el modelo\n",
    "\n",
    ".shuffle(buffer_size) = mezcla elementos dentro de un buffer\n",
    ".prefetch(buffer_size) = precarga un bufer de elementos en la memoria de GPUpara lograr un mejor rendimiento\n",
    ".map(callable) = aplica una transformación a cada elemento del conjunto de datos, toma como entrada un unico elemento del dataset\n",
    ".map() = se utiliza frecuentemente para remodelar la forma del arreglo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(filepath=\"convnet_from_scratch.keras\",\n",
    "                                             save_best_only=True,\n",
    "                                             monitor=\"val_loss\"\n",
    "                                             )\n",
    "]\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=30,\n",
    "                    validation_data = validation_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"bo\", label=\"Validation accuracy\")\n",
    "plt.title(\"train and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, \"bo\", label = \"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label= \"Validaion loss\")\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset) \n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que el modelo está sobre ajustado, el accuracy de entrenamiento es 100% mientres el de validación es de 75%\n",
    "y el de pruebas es de 69%\n",
    "\n",
    "Se utilizarán tecnicas para evitar el sobre ajuste, el más comun es Data augmentation\n",
    "\n",
    "se transforman las imagenes existentes y luego se incluyen en los datos de entrnamiento, esto incrementa los datos y el modelo no ve \n",
    "dos datos iguales ya que son transformados, esto ayuda al modelo a generalizar mejor las caracteristicas\n",
    "\n",
    "También se puede usar Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([layers.RandomFlip(\"horizontal\"), ## voltea la imagen un 50% (espejo)\n",
    "                                      layers.RandomRotation(0.1), ## rota la imagen entre 10% y -10% aleatoreamente \n",
    "                                      layers.RandomZoom(0.2), ## incrementa la imagen en un factor de +-20% aleatoreamente\n",
    "                                      ])\n",
    "\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    " optimizer=\"rmsprop\",\n",
    " metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    " keras.callbacks.ModelCheckpoint(\n",
    " filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
    " save_best_only=True,\n",
    " monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    " train_dataset,\n",
    " epochs=100,\n",
    " validation_data=validation_dataset,\n",
    " callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy ahora varía entre 80% - 85%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
